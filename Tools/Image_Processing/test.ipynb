{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@0.064] global /Users/xperience/actions-runner/_work/opencv-python/opencv-python/opencv/modules/core/src/persistence.cpp (505) open Can't open file: 'cascade.xml' in read mode\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/xperience/actions-runner/_work/opencv-python/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m ret, img \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m     12\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m---> 13\u001b[0m ear \u001b[39m=\u001b[39m ear_cascade\u001b[39m.\u001b[39;49mdetectMultiScale(gray, \u001b[39m1.3\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m (x,y,w,h) \u001b[39min\u001b[39;00m ear:\n\u001b[1;32m     17\u001b[0m     cv2\u001b[39m.\u001b[39mrectangle(img, (x,y), (x\u001b[39m+\u001b[39mw,y\u001b[39m+\u001b[39mh), (\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), \u001b[39m3\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/xperience/actions-runner/_work/opencv-python/opencv-python/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ear_cascade = cv2.CascadeClassifier('cascade.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "  ret, img = cap.read()\n",
    "\n",
    "\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  ear = ear_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "  for (x,y,w,h) in ear:\n",
    "      cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 3)\n",
    "\n",
    "  cv2.imshow('img',img)\n",
    "  k = cv2.waitKey(30) & 0xff\n",
    "  if k == 27:\n",
    "      break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Oct 11 2022, 21:39:54) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimize_prompt import optimize_prompt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial prompt for classification\n",
    "initial_prompt = (\n",
    "    \"You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.\"\n",
    ")\n",
    "\n",
    "# Output format prompt\n",
    "output_format_prompt = (\n",
    "    \"You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for negative. \"\n",
    "    \"Do not include any other text, explanations, or comments.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of optimization iterations\n",
    "iterations = 5  # You can adjust this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the evaluation dataset\n",
    "eval_data = pd.read_csv('reviews.csv', encoding='ISO-8859-1', usecols=['Text', 'Sentiment'])\n",
    "eval_data.columns = ['text', 'label']\n",
    "# Randomly select 50 positive and 50 negative samples, combine without shuffling\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=20, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Sort the DataFrame to ensure incremental index\n",
    "eval_data = eval_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Iteration </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mIteration \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m/\u001b[0m\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────── System Prompt ────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> You are a sentiment analysis classifier. Determine whether the provided text <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> expresses a positive sentiment.  You are to respond strictly in binary       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> format. For each question, reply only with '1' for positive or '0' for       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> negative. Do not include any other text, explanations, or comments.          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰──────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────\u001b[0m\u001b[1m System Prompt \u001b[0m\u001b[1m───────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m expresses a positive sentiment.  You are to respond strictly in binary       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m format. For each question, reply only with '1' for positive or '0' for       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m negative. Do not include any other text, explanations, or comments.          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 2/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 4/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 6/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 8/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 9/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 11/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 12/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 13/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 15/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 16/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 17/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 18/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 19/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 20/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 21/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 22/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 23/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 24/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 25/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 26/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 27/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 28/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 29/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 30/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 31/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 32/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 33/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 34/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 35/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 36/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 37/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 38/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 39/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 40/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "\n",
      "Number of invalid predictions: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8333 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.9091 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8333 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.9091 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> What a fascinating task!                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the misclassifications, I've identified some common patterns and elements that may have         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> contributed to these errors.                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Negative (0) texts incorrectly classified as positive:**                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **\"Shuttle\" review**: The reviewer uses phrases like \"a decent film,\" \"enjoyable for what it is,\" and        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> \"recommend if you have almost 2 hours to kill.\" While the tone is mostly negative, the reviewer's criticisms    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> are balanced with a hint of positivity. This ambiguity may have led the model to misclassify the text as        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"...it would've served the audience better with roughly 15-20 minutes deleted, I would        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recommend if you have almost 2 hours to kill and are into sick horror.\"                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative (0)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **\"Dragon Hunt\" review**: The reviewer uses hyperbole to describe the movie's ridiculousness, but ultimately <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recommends it as a \"great party tape!\" This mix of criticism and enthusiasm may have confused the model.        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"...but then again, it is a great party tape!\"                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive (1)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Sequel review**: The reviewer compares the movie unfavorably to its predecessor but still finds it         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enjoyable for what it is. This nuanced tone may have led the model to misclassify the text as positive.         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"I think that I feel this way possibly because I had high expectations and I have grown up... <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> However, it is not a bad film.\"                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive (1)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **\"The Little Mermaid 2\" review**: The reviewer expresses disappointment with the movie's inability to       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> surpass its original but still finds it enjoyable as a family film. This measured tone may have led the model   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> to misclassify the text as positive.                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"I don't want to give away any of the movie so you have to see it to find out... I think this <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> is a good family film though overall!\"                                                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive (1)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Bad movie rant**: The reviewer's scathing criticism and use of strong language may have led the model to   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> misclassify the text as negative, but the tone is more vitriolic than typical negative reviews.                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"Talk about insulting... Who would green light something so poorly written? This script       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> should have been used to line a bird cage...\"                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative (0)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Positives (1) texts incorrectly classified as negative:**                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> None provided, but based on the analysis above, I suspect that the model may be overly sensitive to criticism   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and dismissive of positive reviews with caveats or qualifications.                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to improve the classification prompt:**                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Emphasize nuance**: The model should be trained to recognize subtle differences in tone and language,      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> particularly when a review is both critical and positive.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Use more context-sensitive features**: Incorporate features that take into account the reviewer's history  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> of posting (e.g., are they known for being harsh or lenient?), the type of content being reviewed (e.g., movie, <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> book, product), and the specific language used in the review.                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Incorporate sentiment analysis with more granular labels**: Instead of just \"positive\" (1) and \"negative\"  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> (0), consider using labels like \"enthusiastic,\" \"mixed,\" or \"critical\" to capture more nuanced sentiments.      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Train on a more diverse dataset**: Expand the training data to include a wider range of texts, including   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> those with mixed or ambiguous sentiment, to improve the model's ability to generalize and recognize subtle      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> differences in tone and language.                                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By implementing these strategies, we can improve the classification prompt's ability to accurately identify     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> both false positives and false negatives, leading to more reliable results.                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m What a fascinating task!                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the misclassifications, I've identified some common patterns and elements that may have         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m contributed to these errors.                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Negative (0) texts incorrectly classified as positive:**                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **\"Shuttle\" review**: The reviewer uses phrases like \"a decent film,\" \"enjoyable for what it is,\" and        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m \"recommend if you have almost 2 hours to kill.\" While the tone is mostly negative, the reviewer's criticisms    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m are balanced with a hint of positivity. This ambiguity may have led the model to misclassify the text as        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"...it would've served the audience better with roughly 15-20 minutes deleted, I would        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recommend if you have almost 2 hours to kill and are into sick horror.\"                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative (0)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **\"Dragon Hunt\" review**: The reviewer uses hyperbole to describe the movie's ridiculousness, but ultimately \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recommends it as a \"great party tape!\" This mix of criticism and enthusiasm may have confused the model.        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"...but then again, it is a great party tape!\"                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive (1)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Sequel review**: The reviewer compares the movie unfavorably to its predecessor but still finds it         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enjoyable for what it is. This nuanced tone may have led the model to misclassify the text as positive.         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"I think that I feel this way possibly because I had high expectations and I have grown up... \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m However, it is not a bad film.\"                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive (1)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **\"The Little Mermaid 2\" review**: The reviewer expresses disappointment with the movie's inability to       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m surpass its original but still finds it enjoyable as a family film. This measured tone may have led the model   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m to misclassify the text as positive.                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"I don't want to give away any of the movie so you have to see it to find out... I think this \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m is a good family film though overall!\"                                                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive (1)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Bad movie rant**: The reviewer's scathing criticism and use of strong language may have led the model to   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m misclassify the text as negative, but the tone is more vitriolic than typical negative reviews.                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"Talk about insulting... Who would green light something so poorly written? This script       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m should have been used to line a bird cage...\"                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative (0)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Positives (1) texts incorrectly classified as negative:**                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m None provided, but based on the analysis above, I suspect that the model may be overly sensitive to criticism   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and dismissive of positive reviews with caveats or qualifications.                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to improve the classification prompt:**                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Emphasize nuance**: The model should be trained to recognize subtle differences in tone and language,      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m particularly when a review is both critical and positive.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Use more context-sensitive features**: Incorporate features that take into account the reviewer's history  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m of posting (e.g., are they known for being harsh or lenient?), the type of content being reviewed (e.g., movie, \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m book, product), and the specific language used in the review.                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Incorporate sentiment analysis with more granular labels**: Instead of just \"positive\" (1) and \"negative\"  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m (0), consider using labels like \"enthusiastic,\" \"mixed,\" or \"critical\" to capture more nuanced sentiments.      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Train on a more diverse dataset**: Expand the training data to include a wider range of texts, including   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m those with mixed or ambiguous sentiment, to improve the model's ability to generalize and recognize subtle      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m differences in tone and language.                                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By implementing these strategies, we can improve the classification prompt's ability to accurately identify     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m both false positives and false negatives, leading to more reliable results.                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────────────────────────────────────────── Prompt Engineer Input ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> binary classification. I will give you the current prompt and an analysis showing where it failed to classify a <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> AI can accurately classify similar texts going forward. The revised prompt should be written in the first       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> person, guiding the AI to handle difficult or edge cases.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Current prompt:                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         You are a sentiment analysis classifier. Determine whether the provided text expresses a positive       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiment.                                                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Analysis of misclassifications:                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         What a fascinating task!                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the misclassifications, I've identified some common patterns and elements that may have         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> contributed to these errors.                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Negative (0) texts incorrectly classified as positive:**                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **\"Shuttle\" review**: The reviewer uses phrases like \"a decent film,\" \"enjoyable for what it is,\" and        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> \"recommend if you have almost 2 hours to kill.\" While the tone is mostly negative, the reviewer's criticisms    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> are balanced with a hint of positivity. This ambiguity may have led the model to misclassify the text as        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"...it would've served the audience better with roughly 15-20 minutes deleted, I would        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recommend if you have almost 2 hours to kill and are into sick horror.\"                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative (0)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **\"Dragon Hunt\" review**: The reviewer uses hyperbole to describe the movie's ridiculousness, but ultimately <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recommends it as a \"great party tape!\" This mix of criticism and enthusiasm may have confused the model.        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"...but then again, it is a great party tape!\"                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive (1)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Sequel review**: The reviewer compares the movie unfavorably to its predecessor but still finds it         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enjoyable for what it is. This nuanced tone may have led the model to misclassify the text as positive.         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"I think that I feel this way possibly because I had high expectations and I have grown up... <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> However, it is not a bad film.\"                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive (1)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **\"The Little Mermaid 2\" review**: The reviewer expresses disappointment with the movie's inability to       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> surpass its original but still finds it enjoyable as a family film. This measured tone may have led the model   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> to misclassify the text as positive.                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"I don't want to give away any of the movie so you have to see it to find out... I think this <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> is a good family film though overall!\"                                                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive (1)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Bad movie rant**: The reviewer's scathing criticism and use of strong language may have led the model to   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> misclassify the text as negative, but the tone is more vitriolic than typical negative reviews.                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Specific example: \"Talk about insulting... Who would green light something so poorly written? This script       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> should have been used to line a bird cage...\"                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative (0)                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Positives (1) texts incorrectly classified as negative:**                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> None provided, but based on the analysis above, I suspect that the model may be overly sensitive to criticism   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and dismissive of positive reviews with caveats or qualifications.                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to improve the classification prompt:**                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Emphasize nuance**: The model should be trained to recognize subtle differences in tone and language,      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> particularly when a review is both critical and positive.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Use more context-sensitive features**: Incorporate features that take into account the reviewer's history  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> of posting (e.g., are they known for being harsh or lenient?), the type of content being reviewed (e.g., movie, <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> book, product), and the specific language used in the review.                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Incorporate sentiment analysis with more granular labels**: Instead of just \"positive\" (1) and \"negative\"  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> (0), consider using labels like \"enthusiastic,\" \"mixed,\" or \"critical\" to capture more nuanced sentiments.      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Train on a more diverse dataset**: Expand the training data to include a wider range of texts, including   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> those with mixed or ambiguous sentiment, to improve the model's ability to generalize and recognize subtle      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> differences in tone and language.                                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By implementing these strategies, we can improve the classification prompt's ability to accurately identify     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> both false positives and false negatives, leading to more reliable results.                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prompt itself.                                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m Prompt Engineer Input \u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m binary classification. I will give you the current prompt and an analysis showing where it failed to classify a \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m AI can accurately classify similar texts going forward. The revised prompt should be written in the first       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m person, guiding the AI to handle difficult or edge cases.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Current prompt:                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         You are a sentiment analysis classifier. Determine whether the provided text expresses a positive       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiment.                                                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Analysis of misclassifications:                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         What a fascinating task!                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the misclassifications, I've identified some common patterns and elements that may have         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m contributed to these errors.                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Negative (0) texts incorrectly classified as positive:**                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **\"Shuttle\" review**: The reviewer uses phrases like \"a decent film,\" \"enjoyable for what it is,\" and        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m \"recommend if you have almost 2 hours to kill.\" While the tone is mostly negative, the reviewer's criticisms    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m are balanced with a hint of positivity. This ambiguity may have led the model to misclassify the text as        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"...it would've served the audience better with roughly 15-20 minutes deleted, I would        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recommend if you have almost 2 hours to kill and are into sick horror.\"                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative (0)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **\"Dragon Hunt\" review**: The reviewer uses hyperbole to describe the movie's ridiculousness, but ultimately \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recommends it as a \"great party tape!\" This mix of criticism and enthusiasm may have confused the model.        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"...but then again, it is a great party tape!\"                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive (1)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Sequel review**: The reviewer compares the movie unfavorably to its predecessor but still finds it         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enjoyable for what it is. This nuanced tone may have led the model to misclassify the text as positive.         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"I think that I feel this way possibly because I had high expectations and I have grown up... \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m However, it is not a bad film.\"                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive (1)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **\"The Little Mermaid 2\" review**: The reviewer expresses disappointment with the movie's inability to       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m surpass its original but still finds it enjoyable as a family film. This measured tone may have led the model   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m to misclassify the text as positive.                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"I don't want to give away any of the movie so you have to see it to find out... I think this \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m is a good family film though overall!\"                                                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive (1)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Bad movie rant**: The reviewer's scathing criticism and use of strong language may have led the model to   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m misclassify the text as negative, but the tone is more vitriolic than typical negative reviews.                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Specific example: \"Talk about insulting... Who would green light something so poorly written? This script       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m should have been used to line a bird cage...\"                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative (0)                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Positives (1) texts incorrectly classified as negative:**                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m None provided, but based on the analysis above, I suspect that the model may be overly sensitive to criticism   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and dismissive of positive reviews with caveats or qualifications.                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to improve the classification prompt:**                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Emphasize nuance**: The model should be trained to recognize subtle differences in tone and language,      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m particularly when a review is both critical and positive.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Use more context-sensitive features**: Incorporate features that take into account the reviewer's history  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m of posting (e.g., are they known for being harsh or lenient?), the type of content being reviewed (e.g., movie, \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m book, product), and the specific language used in the review.                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Incorporate sentiment analysis with more granular labels**: Instead of just \"positive\" (1) and \"negative\"  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m (0), consider using labels like \"enthusiastic,\" \"mixed,\" or \"critical\" to capture more nuanced sentiments.      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Train on a more diverse dataset**: Expand the training data to include a wider range of texts, including   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m those with mixed or ambiguous sentiment, to improve the model's ability to generalize and recognize subtle      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m differences in tone and language.                                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By implementing these strategies, we can improve the classification prompt's ability to accurately identify     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m both false positives and false negatives, leading to more reliable results.                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prompt itself.                                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Iteration </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mIteration \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m/\u001b[0m\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────── System Prompt ───────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Here's a revised prompt:  \"I'm looking for subtle clues in the text. If it  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> expresses an overall tone of enthusiasm, excitement, or approval, classify  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it as 1 (positive). Otherwise, if it conveys criticism, dissatisfaction, or <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> negativity, even if tempered with caveats or qualifications, classify it as <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 0 (negative).\"  You are to respond strictly in binary format. For each      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> question, reply only with '1' for positive or '0' for negative. Do not      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> include any other text, explanations, or comments.                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────\u001b[0m\u001b[1m System Prompt \u001b[0m\u001b[1m──────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Here's a revised prompt:  \"I'm looking for subtle clues in the text. If it  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m expresses an overall tone of enthusiasm, excitement, or approval, classify  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it as 1 (positive). Otherwise, if it conveys criticism, dissatisfaction, or \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m negativity, even if tempered with caveats or qualifications, classify it as \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 0 (negative).\"  You are to respond strictly in binary format. For each      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m question, reply only with '1' for positive or '0' for negative. Do not      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m include any other text, explanations, or comments.                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 2/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 4/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 6/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 8/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 11/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 12/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 13/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 15/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 16/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 17/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 18/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 19/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 20/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 21/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 22/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 23/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 24/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 25/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 26/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 27/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 28/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 29/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 30/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 31/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 32/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 33/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 34/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 35/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 36/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 37/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 38/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 39/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 40/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "\n",
      "Number of invalid predictions: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 2</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8182 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.8500 │\n",
       "│ F1-score            │ 0.8571 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 2\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8182 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.8500 │\n",
       "│ F1-score            │ 0.8571 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the misclassifications, I've identified specific examples where the model made mistakes and     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> highlighted what elements of the text may have led to these errors.                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Example 1: Misclassified as a review of \"The Expendables\" film**                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Error: The text was classified as a movie review instead of a rant or complaint.                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Specific example: The sentence \"DO THESE GANGSTERS WANT THEIR MONEY FETCHED OR NOT???\" is a clear indication  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> that the author is frustrated and annoyed with the plot, rather than providing a neutral or positive review.    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Correct classification: Rant or Complaint                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Analysis: The text's tone, language, and structure suggest a complaint rather than a review. The use of       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rhetorical questions, sarcastic comments, and excessive criticism point to an emotional response, not a         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> balanced evaluation.                                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Example 2: Misclassified as a movie review**                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Error: The text was classified as a movie review instead of a rant or complaint.                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Specific example: The sentence \"I have no idea what drugs he was on when he did it\" suggests the author's     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> strong negative emotions towards the film, rather than providing an objective review.                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Correct classification: Rant or Complaint                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Analysis: Similar to Example 1, the text's tone and language indicate a complaint rather than a review. The   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> use of emotive language, personal attacks (e.g., \"I'd hate to think the script is this bad because of a low     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> I.Q.\"), and explicit criticism point to an emotional response.                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Example 3: Misclassified as a movie review**                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Error: The text was classified as a movie review instead of a rant or complaint.                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Specific example: The sentence \"Paramount Pictures it is up to you to get off your duff and get this film     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> restored now!\" suggests the author's strong emotions towards the company's handling of the film, rather than    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> providing an objective review.                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Correct classification: Rant or Complaint                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Analysis: This text shares similarities with Examples 1 and 2. The use of rhetorical questions, emotive       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> language, and explicit criticism point to a complaint rather than a review.                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to improve the classification prompt**                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> To reduce both false positives (classifying reviews as rants/complaints) and false negatives (missing actual    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rants/complaints), consider the following strategies:                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Improve sentiment analysis**: Develop more nuanced sentiment analysis techniques that can distinguish      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> between strong emotions expressed in a review (e.g., excitement, disappointment) and those expressed in a rant  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> or complaint (e.g., frustration, anger).                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Increase emphasis on tone**: Weight the classification prompt towards recognizing the tone of the text.    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> For example, use natural language processing (NLP) techniques to identify phrases or sentences with strong      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> emotional connotations.                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Enhance contextual understanding**: Incorporate contextual information into the classification process,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> such as:                                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Identifying the author's purpose: Is the author reviewing a movie or expressing dissatisfaction?      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Recognizing the text structure: Are the criticisms organized in a logical manner or presented in a    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> scattered fashion?                                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Use more specific keywords**: Update the keyword list to include phrases and words associated with         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rants/complaints, such as \"I'm so disappointed,\" \"This is ridiculous,\" or \"They completely messed up.\"          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Reduce false positives by emphasizing review characteristics**: When classifying text as a movie review,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prioritize the presence of objective statements, balanced evaluations, and detailed analysis of the film.       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By incorporating these strategies, you can improve the accuracy of text classification and reduce both false    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positives and false negatives.                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the misclassifications, I've identified specific examples where the model made mistakes and     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m highlighted what elements of the text may have led to these errors.                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Example 1: Misclassified as a review of \"The Expendables\" film**                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Error: The text was classified as a movie review instead of a rant or complaint.                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Specific example: The sentence \"DO THESE GANGSTERS WANT THEIR MONEY FETCHED OR NOT???\" is a clear indication  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m that the author is frustrated and annoyed with the plot, rather than providing a neutral or positive review.    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Correct classification: Rant or Complaint                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Analysis: The text's tone, language, and structure suggest a complaint rather than a review. The use of       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rhetorical questions, sarcastic comments, and excessive criticism point to an emotional response, not a         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m balanced evaluation.                                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Example 2: Misclassified as a movie review**                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Error: The text was classified as a movie review instead of a rant or complaint.                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Specific example: The sentence \"I have no idea what drugs he was on when he did it\" suggests the author's     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m strong negative emotions towards the film, rather than providing an objective review.                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Correct classification: Rant or Complaint                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Analysis: Similar to Example 1, the text's tone and language indicate a complaint rather than a review. The   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m use of emotive language, personal attacks (e.g., \"I'd hate to think the script is this bad because of a low     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m I.Q.\"), and explicit criticism point to an emotional response.                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Example 3: Misclassified as a movie review**                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Error: The text was classified as a movie review instead of a rant or complaint.                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Specific example: The sentence \"Paramount Pictures it is up to you to get off your duff and get this film     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m restored now!\" suggests the author's strong emotions towards the company's handling of the film, rather than    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m providing an objective review.                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Correct classification: Rant or Complaint                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Analysis: This text shares similarities with Examples 1 and 2. The use of rhetorical questions, emotive       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m language, and explicit criticism point to a complaint rather than a review.                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to improve the classification prompt**                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m To reduce both false positives (classifying reviews as rants/complaints) and false negatives (missing actual    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rants/complaints), consider the following strategies:                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Improve sentiment analysis**: Develop more nuanced sentiment analysis techniques that can distinguish      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m between strong emotions expressed in a review (e.g., excitement, disappointment) and those expressed in a rant  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m or complaint (e.g., frustration, anger).                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Increase emphasis on tone**: Weight the classification prompt towards recognizing the tone of the text.    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m For example, use natural language processing (NLP) techniques to identify phrases or sentences with strong      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m emotional connotations.                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Enhance contextual understanding**: Incorporate contextual information into the classification process,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m such as:                                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Identifying the author's purpose: Is the author reviewing a movie or expressing dissatisfaction?      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Recognizing the text structure: Are the criticisms organized in a logical manner or presented in a    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m scattered fashion?                                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Use more specific keywords**: Update the keyword list to include phrases and words associated with         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rants/complaints, such as \"I'm so disappointed,\" \"This is ridiculous,\" or \"They completely messed up.\"          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Reduce false positives by emphasizing review characteristics**: When classifying text as a movie review,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prioritize the presence of objective statements, balanced evaluations, and detailed analysis of the film.       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By incorporating these strategies, you can improve the accuracy of text classification and reduce both false    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positives and false negatives.                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────────────────────────────────────────── Prompt Engineer Input ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> binary classification. I will give you the current prompt and an analysis showing where it failed to classify a <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> AI can accurately classify similar texts going forward. The revised prompt should be written in the first       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> person, guiding the AI to handle difficult or edge cases.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Current prompt:                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Here's a revised prompt:                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> \"I'm looking for subtle clues in the text. If it expresses an overall tone of enthusiasm, excitement, or        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> approval, classify it as 1 (positive). Otherwise, if it conveys criticism, dissatisfaction, or negativity, even <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> if tempered with caveats or qualifications, classify it as 0 (negative).\"                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Analysis of misclassifications:                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         After analyzing the misclassifications, I've identified specific examples where the model made mistakes <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and highlighted what elements of the text may have led to these errors.                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Example 1: Misclassified as a review of \"The Expendables\" film**                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Error: The text was classified as a movie review instead of a rant or complaint.                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Specific example: The sentence \"DO THESE GANGSTERS WANT THEIR MONEY FETCHED OR NOT???\" is a clear indication  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> that the author is frustrated and annoyed with the plot, rather than providing a neutral or positive review.    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Correct classification: Rant or Complaint                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Analysis: The text's tone, language, and structure suggest a complaint rather than a review. The use of       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rhetorical questions, sarcastic comments, and excessive criticism point to an emotional response, not a         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> balanced evaluation.                                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Example 2: Misclassified as a movie review**                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Error: The text was classified as a movie review instead of a rant or complaint.                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Specific example: The sentence \"I have no idea what drugs he was on when he did it\" suggests the author's     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> strong negative emotions towards the film, rather than providing an objective review.                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Correct classification: Rant or Complaint                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Analysis: Similar to Example 1, the text's tone and language indicate a complaint rather than a review. The   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> use of emotive language, personal attacks (e.g., \"I'd hate to think the script is this bad because of a low     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> I.Q.\"), and explicit criticism point to an emotional response.                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Example 3: Misclassified as a movie review**                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Error: The text was classified as a movie review instead of a rant or complaint.                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Specific example: The sentence \"Paramount Pictures it is up to you to get off your duff and get this film     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> restored now!\" suggests the author's strong emotions towards the company's handling of the film, rather than    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> providing an objective review.                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Correct classification: Rant or Complaint                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * Analysis: This text shares similarities with Examples 1 and 2. The use of rhetorical questions, emotive       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> language, and explicit criticism point to a complaint rather than a review.                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to improve the classification prompt**                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> To reduce both false positives (classifying reviews as rants/complaints) and false negatives (missing actual    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rants/complaints), consider the following strategies:                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Improve sentiment analysis**: Develop more nuanced sentiment analysis techniques that can distinguish      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> between strong emotions expressed in a review (e.g., excitement, disappointment) and those expressed in a rant  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> or complaint (e.g., frustration, anger).                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Increase emphasis on tone**: Weight the classification prompt towards recognizing the tone of the text.    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> For example, use natural language processing (NLP) techniques to identify phrases or sentences with strong      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> emotional connotations.                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Enhance contextual understanding**: Incorporate contextual information into the classification process,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> such as:                                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Identifying the author's purpose: Is the author reviewing a movie or expressing dissatisfaction?      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Recognizing the text structure: Are the criticisms organized in a logical manner or presented in a    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> scattered fashion?                                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Use more specific keywords**: Update the keyword list to include phrases and words associated with         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rants/complaints, such as \"I'm so disappointed,\" \"This is ridiculous,\" or \"They completely messed up.\"          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Reduce false positives by emphasizing review characteristics**: When classifying text as a movie review,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prioritize the presence of objective statements, balanced evaluations, and detailed analysis of the film.       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By incorporating these strategies, you can improve the accuracy of text classification and reduce both false    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positives and false negatives.                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prompt itself.                                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m Prompt Engineer Input \u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m binary classification. I will give you the current prompt and an analysis showing where it failed to classify a \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m AI can accurately classify similar texts going forward. The revised prompt should be written in the first       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m person, guiding the AI to handle difficult or edge cases.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Current prompt:                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Here's a revised prompt:                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m \"I'm looking for subtle clues in the text. If it expresses an overall tone of enthusiasm, excitement, or        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m approval, classify it as 1 (positive). Otherwise, if it conveys criticism, dissatisfaction, or negativity, even \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m if tempered with caveats or qualifications, classify it as 0 (negative).\"                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Analysis of misclassifications:                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         After analyzing the misclassifications, I've identified specific examples where the model made mistakes \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and highlighted what elements of the text may have led to these errors.                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Example 1: Misclassified as a review of \"The Expendables\" film**                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Error: The text was classified as a movie review instead of a rant or complaint.                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Specific example: The sentence \"DO THESE GANGSTERS WANT THEIR MONEY FETCHED OR NOT???\" is a clear indication  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m that the author is frustrated and annoyed with the plot, rather than providing a neutral or positive review.    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Correct classification: Rant or Complaint                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Analysis: The text's tone, language, and structure suggest a complaint rather than a review. The use of       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rhetorical questions, sarcastic comments, and excessive criticism point to an emotional response, not a         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m balanced evaluation.                                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Example 2: Misclassified as a movie review**                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Error: The text was classified as a movie review instead of a rant or complaint.                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Specific example: The sentence \"I have no idea what drugs he was on when he did it\" suggests the author's     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m strong negative emotions towards the film, rather than providing an objective review.                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Correct classification: Rant or Complaint                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Analysis: Similar to Example 1, the text's tone and language indicate a complaint rather than a review. The   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m use of emotive language, personal attacks (e.g., \"I'd hate to think the script is this bad because of a low     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m I.Q.\"), and explicit criticism point to an emotional response.                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Example 3: Misclassified as a movie review**                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Error: The text was classified as a movie review instead of a rant or complaint.                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Specific example: The sentence \"Paramount Pictures it is up to you to get off your duff and get this film     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m restored now!\" suggests the author's strong emotions towards the company's handling of the film, rather than    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m providing an objective review.                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Correct classification: Rant or Complaint                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * Analysis: This text shares similarities with Examples 1 and 2. The use of rhetorical questions, emotive       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m language, and explicit criticism point to a complaint rather than a review.                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to improve the classification prompt**                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m To reduce both false positives (classifying reviews as rants/complaints) and false negatives (missing actual    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rants/complaints), consider the following strategies:                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Improve sentiment analysis**: Develop more nuanced sentiment analysis techniques that can distinguish      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m between strong emotions expressed in a review (e.g., excitement, disappointment) and those expressed in a rant  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m or complaint (e.g., frustration, anger).                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Increase emphasis on tone**: Weight the classification prompt towards recognizing the tone of the text.    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m For example, use natural language processing (NLP) techniques to identify phrases or sentences with strong      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m emotional connotations.                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Enhance contextual understanding**: Incorporate contextual information into the classification process,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m such as:                                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Identifying the author's purpose: Is the author reviewing a movie or expressing dissatisfaction?      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Recognizing the text structure: Are the criticisms organized in a logical manner or presented in a    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m scattered fashion?                                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Use more specific keywords**: Update the keyword list to include phrases and words associated with         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rants/complaints, such as \"I'm so disappointed,\" \"This is ridiculous,\" or \"They completely messed up.\"          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Reduce false positives by emphasizing review characteristics**: When classifying text as a movie review,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prioritize the presence of objective statements, balanced evaluations, and detailed analysis of the film.       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By incorporating these strategies, you can improve the accuracy of text classification and reduce both false    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positives and false negatives.                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prompt itself.                                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Iteration </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mIteration \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m/\u001b[0m\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────── System Prompt ────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Here's the revised prompt:  \"I'm looking for subtle clues in the text. If it <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> expresses an overall tone of enthusiasm, excitement, or approval, classify   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it as 1 (positive). However, if it conveys criticism, dissatisfaction, or    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> negativity, even if tempered with caveats or qualifications, especially when <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> characterized by rhetorical questions, emotive language, personal attacks,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and explicit criticism, classify it as 0 (negative). Be cautious of false    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positives in reviews; prioritize the presence of objective statements,       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> balanced evaluations, and detailed analysis. If the text appears to be a     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rant or complaint, pay attention to its tone, structure, and author's        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> purpose.\"  You are to respond strictly in binary format. For each question,  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> reply only with '1' for positive or '0' for negative. Do not include any     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> other text, explanations, or comments.                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰──────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────\u001b[0m\u001b[1m System Prompt \u001b[0m\u001b[1m───────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Here's the revised prompt:  \"I'm looking for subtle clues in the text. If it \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m expresses an overall tone of enthusiasm, excitement, or approval, classify   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it as 1 (positive). However, if it conveys criticism, dissatisfaction, or    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m negativity, even if tempered with caveats or qualifications, especially when \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m characterized by rhetorical questions, emotive language, personal attacks,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and explicit criticism, classify it as 0 (negative). Be cautious of false    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positives in reviews; prioritize the presence of objective statements,       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m balanced evaluations, and detailed analysis. If the text appears to be a     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rant or complaint, pay attention to its tone, structure, and author's        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m purpose.\"  You are to respond strictly in binary format. For each question,  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m reply only with '1' for positive or '0' for negative. Do not include any     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m other text, explanations, or comments.                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 2/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 4/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 6/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 8/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 11/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 12/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 13/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 15/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 16/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 17/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 18/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 19/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 20/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 21/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 22/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 23/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 24/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 25/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 26/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 27/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 28/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 29/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 30/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 31/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 32/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 33/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 34/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 35/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 36/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 37/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 38/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 39/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 40/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "\n",
      "Number of invalid predictions: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 3</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8571 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.8750 │\n",
       "│ F1-score            │ 0.8780 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 3\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.8571 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.8750 │\n",
       "│ F1-score            │ 0.8780 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the two misclassifications, I've identified specific examples where the model made mistakes and <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> highlighted what elements of the text may have led to the incorrect classification.                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Misclassification 1: Incorrectly classifying a review of an action movie as \"pirate-themed\"**                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> The review is actually about the movie \" Cliffhanger (1993)\" directed by Renny Harlin, starring Sylvester       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Stallone. The text describes various aspects of the movie, including its plot, characters, and action           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sequences.                                                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Specific examples of mistakes:**                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The model incorrectly identified the theme as pirate-themed, despite the review mentioning nothing    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> about pirates.                                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The text contains references to an airplane hijacking, a snowy mountainous setting, and Sylvester     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Stallone's character, which suggests an action movie rather than a pirate-themed film.                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Correct classification:** \"Action movie review\"                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Insight:** The model may have been misled by the mention of a \"tango-tango\" codename for the villains,      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> which was actually a reference to their radio call sign. This might have caused the model to incorrectly assume <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> a connection to pirate-themed movies.                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Misclassification 2: Incorrectly classifying a complaint about Paramount Pictures' restoration of an old      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> movie as a review of \"Cliffhanger (1993)\"**                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> The text is actually a frustrated statement from someone who wants Paramount Pictures to restore and release    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> another old movie, directed by Anthony Quinn, supervised by Cecil B. DeMille.                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Specific examples of mistakes:**                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The model incorrectly assumed the text was about \"Cliffhanger (1993)\", despite the mention of a       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> different director and supervising producer.                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The tone of the text is more like a complaint or a request for action, rather than a review of an     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> actual movie experience.                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Correct classification:** \"Complaint/Request for release of old movie\"                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Insight:** The model may have been misled by the mention of Paramount Pictures and the phrase \"Crescent     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> City\", which could be interpreted as a reference to New Orleans, where \"Cliffhanger (1993)\" was set. However,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> in this context, it seems to refer to another city, not related to the movie.                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies for improving the classification prompt:**                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Make the prompt more specific:** Instead of using broad categories like \"pirate-themed\" or \"action movie   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> review\", consider asking more targeted questions about specific aspects of the text, such as plot elements,     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> character types, or tone.                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Increase sensitivity to subtle differences:** The model should be able to distinguish between different    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> nuances in language and recognize when a reference might have multiple interpretations (e.g., \"tango-tango\"     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> being both a radio call sign and a pirate-themed element).                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Train the model on more diverse data:** Include a broader range of text types, including complaints,       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> requests for release, and other genres, to help the model develop a more nuanced understanding of language.     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Use more advanced natural language processing techniques:** Consider using techniques like named entity    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recognition (NER), sentiment analysis, or topic modeling to better capture the essence of each text.            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By implementing these strategies, you can reduce both false positives and false negatives, making the           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classification prompt more effective at recognizing subtle differences in language and improving overall        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> accuracy.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the two misclassifications, I've identified specific examples where the model made mistakes and \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m highlighted what elements of the text may have led to the incorrect classification.                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Misclassification 1: Incorrectly classifying a review of an action movie as \"pirate-themed\"**                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m The review is actually about the movie \" Cliffhanger (1993)\" directed by Renny Harlin, starring Sylvester       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Stallone. The text describes various aspects of the movie, including its plot, characters, and action           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sequences.                                                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Specific examples of mistakes:**                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The model incorrectly identified the theme as pirate-themed, despite the review mentioning nothing    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m about pirates.                                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The text contains references to an airplane hijacking, a snowy mountainous setting, and Sylvester     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Stallone's character, which suggests an action movie rather than a pirate-themed film.                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Correct classification:** \"Action movie review\"                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Insight:** The model may have been misled by the mention of a \"tango-tango\" codename for the villains,      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m which was actually a reference to their radio call sign. This might have caused the model to incorrectly assume \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m a connection to pirate-themed movies.                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Misclassification 2: Incorrectly classifying a complaint about Paramount Pictures' restoration of an old      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m movie as a review of \"Cliffhanger (1993)\"**                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m The text is actually a frustrated statement from someone who wants Paramount Pictures to restore and release    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m another old movie, directed by Anthony Quinn, supervised by Cecil B. DeMille.                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Specific examples of mistakes:**                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The model incorrectly assumed the text was about \"Cliffhanger (1993)\", despite the mention of a       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m different director and supervising producer.                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The tone of the text is more like a complaint or a request for action, rather than a review of an     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m actual movie experience.                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Correct classification:** \"Complaint/Request for release of old movie\"                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Insight:** The model may have been misled by the mention of Paramount Pictures and the phrase \"Crescent     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m City\", which could be interpreted as a reference to New Orleans, where \"Cliffhanger (1993)\" was set. However,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m in this context, it seems to refer to another city, not related to the movie.                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies for improving the classification prompt:**                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Make the prompt more specific:** Instead of using broad categories like \"pirate-themed\" or \"action movie   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m review\", consider asking more targeted questions about specific aspects of the text, such as plot elements,     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m character types, or tone.                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Increase sensitivity to subtle differences:** The model should be able to distinguish between different    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m nuances in language and recognize when a reference might have multiple interpretations (e.g., \"tango-tango\"     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m being both a radio call sign and a pirate-themed element).                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Train the model on more diverse data:** Include a broader range of text types, including complaints,       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m requests for release, and other genres, to help the model develop a more nuanced understanding of language.     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Use more advanced natural language processing techniques:** Consider using techniques like named entity    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recognition (NER), sentiment analysis, or topic modeling to better capture the essence of each text.            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By implementing these strategies, you can reduce both false positives and false negatives, making the           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classification prompt more effective at recognizing subtle differences in language and improving overall        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m accuracy.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────────────────────────────────────────── Prompt Engineer Input ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> binary classification. I will give you the current prompt and an analysis showing where it failed to classify a <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> AI can accurately classify similar texts going forward. The revised prompt should be written in the first       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> person, guiding the AI to handle difficult or edge cases.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Current prompt:                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Here's the revised prompt:                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> \"I'm looking for subtle clues in the text. If it expresses an overall tone of enthusiasm, excitement, or        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> approval, classify it as 1 (positive). However, if it conveys criticism, dissatisfaction, or negativity, even   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> if tempered with caveats or qualifications, especially when characterized by rhetorical questions, emotive      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> language, personal attacks, and explicit criticism, classify it as 0 (negative). Be cautious of false positives <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> in reviews; prioritize the presence of objective statements, balanced evaluations, and detailed analysis. If    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the text appears to be a rant or complaint, pay attention to its tone, structure, and author's purpose.\"        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Analysis of misclassifications:                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         After analyzing the two misclassifications, I've identified specific examples where the model made      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> mistakes and highlighted what elements of the text may have led to the incorrect classification.                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Misclassification 1: Incorrectly classifying a review of an action movie as \"pirate-themed\"**                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> The review is actually about the movie \" Cliffhanger (1993)\" directed by Renny Harlin, starring Sylvester       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Stallone. The text describes various aspects of the movie, including its plot, characters, and action           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sequences.                                                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Specific examples of mistakes:**                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The model incorrectly identified the theme as pirate-themed, despite the review mentioning nothing    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> about pirates.                                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The text contains references to an airplane hijacking, a snowy mountainous setting, and Sylvester     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Stallone's character, which suggests an action movie rather than a pirate-themed film.                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Correct classification:** \"Action movie review\"                                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Insight:** The model may have been misled by the mention of a \"tango-tango\" codename for the villains,      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> which was actually a reference to their radio call sign. This might have caused the model to incorrectly assume <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> a connection to pirate-themed movies.                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Misclassification 2: Incorrectly classifying a complaint about Paramount Pictures' restoration of an old      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> movie as a review of \"Cliffhanger (1993)\"**                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> The text is actually a frustrated statement from someone who wants Paramount Pictures to restore and release    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> another old movie, directed by Anthony Quinn, supervised by Cecil B. DeMille.                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Specific examples of mistakes:**                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The model incorrectly assumed the text was about \"Cliffhanger (1993)\", despite the mention of a       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> different director and supervising producer.                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         + The tone of the text is more like a complaint or a request for action, rather than a review of an     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> actual movie experience.                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Correct classification:** \"Complaint/Request for release of old movie\"                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> * **Insight:** The model may have been misled by the mention of Paramount Pictures and the phrase \"Crescent     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> City\", which could be interpreted as a reference to New Orleans, where \"Cliffhanger (1993)\" was set. However,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> in this context, it seems to refer to another city, not related to the movie.                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies for improving the classification prompt:**                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Make the prompt more specific:** Instead of using broad categories like \"pirate-themed\" or \"action movie   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> review\", consider asking more targeted questions about specific aspects of the text, such as plot elements,     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> character types, or tone.                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Increase sensitivity to subtle differences:** The model should be able to distinguish between different    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> nuances in language and recognize when a reference might have multiple interpretations (e.g., \"tango-tango\"     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> being both a radio call sign and a pirate-themed element).                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Train the model on more diverse data:** Include a broader range of text types, including complaints,       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> requests for release, and other genres, to help the model develop a more nuanced understanding of language.     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Use more advanced natural language processing techniques:** Consider using techniques like named entity    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> recognition (NER), sentiment analysis, or topic modeling to better capture the essence of each text.            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By implementing these strategies, you can reduce both false positives and false negatives, making the           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classification prompt more effective at recognizing subtle differences in language and improving overall        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> accuracy.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prompt itself.                                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m Prompt Engineer Input \u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m binary classification. I will give you the current prompt and an analysis showing where it failed to classify a \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m AI can accurately classify similar texts going forward. The revised prompt should be written in the first       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m person, guiding the AI to handle difficult or edge cases.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Current prompt:                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Here's the revised prompt:                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m \"I'm looking for subtle clues in the text. If it expresses an overall tone of enthusiasm, excitement, or        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m approval, classify it as 1 (positive). However, if it conveys criticism, dissatisfaction, or negativity, even   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m if tempered with caveats or qualifications, especially when characterized by rhetorical questions, emotive      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m language, personal attacks, and explicit criticism, classify it as 0 (negative). Be cautious of false positives \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m in reviews; prioritize the presence of objective statements, balanced evaluations, and detailed analysis. If    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the text appears to be a rant or complaint, pay attention to its tone, structure, and author's purpose.\"        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Analysis of misclassifications:                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         After analyzing the two misclassifications, I've identified specific examples where the model made      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m mistakes and highlighted what elements of the text may have led to the incorrect classification.                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Misclassification 1: Incorrectly classifying a review of an action movie as \"pirate-themed\"**                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m The review is actually about the movie \" Cliffhanger (1993)\" directed by Renny Harlin, starring Sylvester       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Stallone. The text describes various aspects of the movie, including its plot, characters, and action           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sequences.                                                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Specific examples of mistakes:**                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The model incorrectly identified the theme as pirate-themed, despite the review mentioning nothing    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m about pirates.                                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The text contains references to an airplane hijacking, a snowy mountainous setting, and Sylvester     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Stallone's character, which suggests an action movie rather than a pirate-themed film.                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Correct classification:** \"Action movie review\"                                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Insight:** The model may have been misled by the mention of a \"tango-tango\" codename for the villains,      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m which was actually a reference to their radio call sign. This might have caused the model to incorrectly assume \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m a connection to pirate-themed movies.                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Misclassification 2: Incorrectly classifying a complaint about Paramount Pictures' restoration of an old      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m movie as a review of \"Cliffhanger (1993)\"**                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m The text is actually a frustrated statement from someone who wants Paramount Pictures to restore and release    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m another old movie, directed by Anthony Quinn, supervised by Cecil B. DeMille.                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Specific examples of mistakes:**                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The model incorrectly assumed the text was about \"Cliffhanger (1993)\", despite the mention of a       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m different director and supervising producer.                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         + The tone of the text is more like a complaint or a request for action, rather than a review of an     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m actual movie experience.                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Correct classification:** \"Complaint/Request for release of old movie\"                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m * **Insight:** The model may have been misled by the mention of Paramount Pictures and the phrase \"Crescent     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m City\", which could be interpreted as a reference to New Orleans, where \"Cliffhanger (1993)\" was set. However,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m in this context, it seems to refer to another city, not related to the movie.                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies for improving the classification prompt:**                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Make the prompt more specific:** Instead of using broad categories like \"pirate-themed\" or \"action movie   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m review\", consider asking more targeted questions about specific aspects of the text, such as plot elements,     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m character types, or tone.                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Increase sensitivity to subtle differences:** The model should be able to distinguish between different    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m nuances in language and recognize when a reference might have multiple interpretations (e.g., \"tango-tango\"     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m being both a radio call sign and a pirate-themed element).                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Train the model on more diverse data:** Include a broader range of text types, including complaints,       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m requests for release, and other genres, to help the model develop a more nuanced understanding of language.     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Use more advanced natural language processing techniques:** Consider using techniques like named entity    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m recognition (NER), sentiment analysis, or topic modeling to better capture the essence of each text.            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By implementing these strategies, you can reduce both false positives and false negatives, making the           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classification prompt more effective at recognizing subtle differences in language and improving overall        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m accuracy.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prompt itself.                                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Iteration </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mIteration \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m/\u001b[0m\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────── System Prompt ────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Here's the refined prompt:  \"I'm searching for subtle clues in the text.     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Classify it as 1 (positive) if it conveys enthusiasm, excitement, or         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> approval about a movie, product, or experience, and explicitly mentions its  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> plot, characters, settings, or features. However, classify it as 0           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> (negative) if it expresses criticism, dissatisfaction, or negativity towards <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> an entity, even with caveats or qualifications, especially when              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> characterized by rhetorical questions, emotive language, personal attacks,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and explicit criticism. Be cautious of false positives in reviews;           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prioritize the presence of objective statements, balanced evaluations, and   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> detailed analysis. If the text appears to be a rant or complaint, pay        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> attention to its tone, structure, and author's purpose. Specifically,        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> consider whether the text mentions specific plot points, character           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> interactions, or settings that align with the genre (e.g., action movie),    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and take note of any requests for release, restoration, or improvement       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> related to an old movie or entity.\"  You are to respond strictly in binary   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> format. For each question, reply only with '1' for positive or '0' for       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> negative. Do not include any other text, explanations, or comments.          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰──────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────\u001b[0m\u001b[1m System Prompt \u001b[0m\u001b[1m───────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Here's the refined prompt:  \"I'm searching for subtle clues in the text.     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Classify it as 1 (positive) if it conveys enthusiasm, excitement, or         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m approval about a movie, product, or experience, and explicitly mentions its  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m plot, characters, settings, or features. However, classify it as 0           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m (negative) if it expresses criticism, dissatisfaction, or negativity towards \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m an entity, even with caveats or qualifications, especially when              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m characterized by rhetorical questions, emotive language, personal attacks,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and explicit criticism. Be cautious of false positives in reviews;           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prioritize the presence of objective statements, balanced evaluations, and   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m detailed analysis. If the text appears to be a rant or complaint, pay        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m attention to its tone, structure, and author's purpose. Specifically,        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m consider whether the text mentions specific plot points, character           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m interactions, or settings that align with the genre (e.g., action movie),    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and take note of any requests for release, restoration, or improvement       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m related to an old movie or entity.\"  You are to respond strictly in binary   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m format. For each question, reply only with '1' for positive or '0' for       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m negative. Do not include any other text, explanations, or comments.          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 2/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 4/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 6/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 8/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 11/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 12/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 13/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 15/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 16/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 17/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 18/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 19/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 20/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 21/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 22/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 23/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 24/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 25/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 26/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 27/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 28/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 29/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 30/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 31/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 32/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 33/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 34/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 35/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 36/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 37/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 38/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 39/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 40/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "\n",
      "Number of invalid predictions: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 4</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.9000 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.9000 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 4\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.9000 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.9000 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Analysis of Misclassifications**                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> The provided texts demonstrate a range of misclassifications, including:                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Negative texts classified as positive:**                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 1 (Movie Review): The text describes a movie as \"one of the cheapest action flicks of the     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> eighties\" and states it's \"really awful,\" but also mentions it's a \"great party tape.\" The model incorrectly    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classified this review as positive, likely due to the tone being more playful and humorous than negative.       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 2 (Sequel Review): This text discusses a movie that didn't live up to expectations, stating   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it's \"not a bad film\" but also mentions it's \"like most sequels.\" The model misclassified this review as        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive, possibly due to the reviewer's lukewarm tone and emphasis on its family-friendly nature.              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Positive texts classified as negative:**                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 3 (Movie Review): This text discusses a movie with a ridiculous plot, bad dialogue, and silly <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> characters, but also highlights its entertaining aspects, such as suspense and action sequences. The model      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> incorrectly classified this review as negative, likely due to the focus on the movie's flaws rather than its    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enjoyable qualities.                                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 4 (Historical Context Complaint): This text expresses disappointment with Paramount Pictures' <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> handling of a historical movie, criticizing their restoration efforts and lack of recognition for a real pirate <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> who lived in New Orleans. The model misclassified this complaint as negative, possibly due to the tone being    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> more critical than positive.                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Correct Classifications**                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> For each example:                                                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Example 1**: Correct classification should be Negative (0)                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Example 2**: Correct classification should be Positive (1) with a nuance: it's a mediocre movie that       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> didn't live up to expectations, but still enjoyable for some.                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Example 3**: Correct classification should be Positive (1), highlighting the movie's entertaining aspects  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and flaws as a sign of its campy appeal.                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Example 4**: Correct classification should be Negative (0), emphasizing the complainant's disappointment   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> with Paramount Pictures' handling of a historical movie.                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to Improve Classification Prompt**                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> To reduce false positives and false negatives, consider the following adjustments:                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Tone Analysis**: Incorporate tone analysis techniques into the prompt to better capture the nuances of     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> language. This can help distinguish between playful or humorous texts that are still negative and those that    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> genuinely express enthusiasm.                                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Emphasis on Specifics**: Encourage the model to focus on specific details in the text, such as plot        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> elements, character development, or historical context. This can help identify whether a review is primarily    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive or negative.                                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Contextual Understanding**: Add contextual understanding to the prompt by incorporating information about  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the movie's genre, target audience, and release date. This can help the model recognize that a negative review  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> might still be enjoyable for some viewers.                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Sentiment Polarity**: Refine the sentiment polarity analysis in the prompt to account for subtle           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> differences between positive and negative sentiments. This can involve identifying nuance in language, such as  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> using words like \"awful\" versus \"bad.\"                                                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Regular Training Data Updates**: Regularly update the training data with new texts that reflect different  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> genres, styles, and linguistic variations. This will help ensure the model remains accurate and adaptable to    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> changing language patterns.                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By incorporating these strategies into the classification prompt, you can improve its accuracy in recognizing   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the nuances of language and reduce false positives and false negatives.                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Analysis of Misclassifications**                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m The provided texts demonstrate a range of misclassifications, including:                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Negative texts classified as positive:**                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 1 (Movie Review): The text describes a movie as \"one of the cheapest action flicks of the     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m eighties\" and states it's \"really awful,\" but also mentions it's a \"great party tape.\" The model incorrectly    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classified this review as positive, likely due to the tone being more playful and humorous than negative.       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 2 (Sequel Review): This text discusses a movie that didn't live up to expectations, stating   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it's \"not a bad film\" but also mentions it's \"like most sequels.\" The model misclassified this review as        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive, possibly due to the reviewer's lukewarm tone and emphasis on its family-friendly nature.              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Positive texts classified as negative:**                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 3 (Movie Review): This text discusses a movie with a ridiculous plot, bad dialogue, and silly \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m characters, but also highlights its entertaining aspects, such as suspense and action sequences. The model      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m incorrectly classified this review as negative, likely due to the focus on the movie's flaws rather than its    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enjoyable qualities.                                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 4 (Historical Context Complaint): This text expresses disappointment with Paramount Pictures' \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m handling of a historical movie, criticizing their restoration efforts and lack of recognition for a real pirate \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m who lived in New Orleans. The model misclassified this complaint as negative, possibly due to the tone being    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m more critical than positive.                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Correct Classifications**                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m For each example:                                                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Example 1**: Correct classification should be Negative (0)                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Example 2**: Correct classification should be Positive (1) with a nuance: it's a mediocre movie that       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m didn't live up to expectations, but still enjoyable for some.                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Example 3**: Correct classification should be Positive (1), highlighting the movie's entertaining aspects  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and flaws as a sign of its campy appeal.                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Example 4**: Correct classification should be Negative (0), emphasizing the complainant's disappointment   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m with Paramount Pictures' handling of a historical movie.                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to Improve Classification Prompt**                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m To reduce false positives and false negatives, consider the following adjustments:                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Tone Analysis**: Incorporate tone analysis techniques into the prompt to better capture the nuances of     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m language. This can help distinguish between playful or humorous texts that are still negative and those that    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m genuinely express enthusiasm.                                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Emphasis on Specifics**: Encourage the model to focus on specific details in the text, such as plot        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m elements, character development, or historical context. This can help identify whether a review is primarily    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive or negative.                                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Contextual Understanding**: Add contextual understanding to the prompt by incorporating information about  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the movie's genre, target audience, and release date. This can help the model recognize that a negative review  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m might still be enjoyable for some viewers.                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Sentiment Polarity**: Refine the sentiment polarity analysis in the prompt to account for subtle           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m differences between positive and negative sentiments. This can involve identifying nuance in language, such as  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m using words like \"awful\" versus \"bad.\"                                                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Regular Training Data Updates**: Regularly update the training data with new texts that reflect different  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m genres, styles, and linguistic variations. This will help ensure the model remains accurate and adaptable to    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m changing language patterns.                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By incorporating these strategies into the classification prompt, you can improve its accuracy in recognizing   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the nuances of language and reduce false positives and false negatives.                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭───────────────────────────────────────────── Prompt Engineer Input ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> binary classification. I will give you the current prompt and an analysis showing where it failed to classify a <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> AI can accurately classify similar texts going forward. The revised prompt should be written in the first       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> person, guiding the AI to handle difficult or edge cases.                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Current prompt:                                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Here's the refined prompt:                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> \"I'm searching for subtle clues in the text. Classify it as 1 (positive) if it conveys enthusiasm, excitement,  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> or approval about a movie, product, or experience, and explicitly mentions its plot, characters, settings, or   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> features. However, classify it as 0 (negative) if it expresses criticism, dissatisfaction, or negativity        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> towards an entity, even with caveats or qualifications, especially when characterized by rhetorical questions,  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> emotive language, personal attacks, and explicit criticism. Be cautious of false positives in reviews;          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prioritize the presence of objective statements, balanced evaluations, and detailed analysis. If the text       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> appears to be a rant or complaint, pay attention to its tone, structure, and author's purpose. Specifically,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> consider whether the text mentions specific plot points, character interactions, or settings that align with    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the genre (e.g., action movie), and take note of any requests for release, restoration, or improvement related  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> to an old movie or entity.\"                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Analysis of misclassifications:                                                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         **Analysis of Misclassifications**                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> The provided texts demonstrate a range of misclassifications, including:                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Negative texts classified as positive:**                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 1 (Movie Review): The text describes a movie as \"one of the cheapest action flicks of the     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> eighties\" and states it's \"really awful,\" but also mentions it's a \"great party tape.\" The model incorrectly    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classified this review as positive, likely due to the tone being more playful and humorous than negative.       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 2 (Sequel Review): This text discusses a movie that didn't live up to expectations, stating   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it's \"not a bad film\" but also mentions it's \"like most sequels.\" The model misclassified this review as        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive, possibly due to the reviewer's lukewarm tone and emphasis on its family-friendly nature.              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Positive texts classified as negative:**                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 3 (Movie Review): This text discusses a movie with a ridiculous plot, bad dialogue, and silly <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> characters, but also highlights its entertaining aspects, such as suspense and action sequences. The model      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> incorrectly classified this review as negative, likely due to the focus on the movie's flaws rather than its    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enjoyable qualities.                                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         * Example 4 (Historical Context Complaint): This text expresses disappointment with Paramount Pictures' <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> handling of a historical movie, criticizing their restoration efforts and lack of recognition for a real pirate <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> who lived in New Orleans. The model misclassified this complaint as negative, possibly due to the tone being    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> more critical than positive.                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Correct Classifications**                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> For each example:                                                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Example 1**: Correct classification should be Negative (0)                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Example 2**: Correct classification should be Positive (1) with a nuance: it's a mediocre movie that       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> didn't live up to expectations, but still enjoyable for some.                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Example 3**: Correct classification should be Positive (1), highlighting the movie's entertaining aspects  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and flaws as a sign of its campy appeal.                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Example 4**: Correct classification should be Negative (0), emphasizing the complainant's disappointment   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> with Paramount Pictures' handling of a historical movie.                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to Improve Classification Prompt**                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> To reduce false positives and false negatives, consider the following adjustments:                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Tone Analysis**: Incorporate tone analysis techniques into the prompt to better capture the nuances of     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> language. This can help distinguish between playful or humorous texts that are still negative and those that    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> genuinely express enthusiasm.                                                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Emphasis on Specifics**: Encourage the model to focus on specific details in the text, such as plot        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> elements, character development, or historical context. This can help identify whether a review is primarily    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> positive or negative.                                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Contextual Understanding**: Add contextual understanding to the prompt by incorporating information about  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the movie's genre, target audience, and release date. This can help the model recognize that a negative review  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> might still be enjoyable for some viewers.                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Sentiment Polarity**: Refine the sentiment polarity analysis in the prompt to account for subtle           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> differences between positive and negative sentiments. This can involve identifying nuance in language, such as  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> using words like \"awful\" versus \"bad.\"                                                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 5. **Regular Training Data Updates**: Regularly update the training data with new texts that reflect different  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> genres, styles, and linguistic variations. This will help ensure the model remains accurate and adaptable to    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> changing language patterns.                                                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By incorporating these strategies into the classification prompt, you can improve its accuracy in recognizing   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> the nuances of language and reduce false positives and false negatives.                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prompt itself.                                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m Prompt Engineer Input \u001b[0m\u001b[1m────────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         You are an expert in crafting highly effective prompts. Your task is to help me improve a prompt for    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m binary classification. I will give you the current prompt and an analysis showing where it failed to classify a \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m piece of text correctly. Your goal is to refine the prompt to be more precise and adaptable, ensuring that the  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m AI can accurately classify similar texts going forward. The revised prompt should be written in the first       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m person, guiding the AI to handle difficult or edge cases.                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Current prompt:                                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Here's the refined prompt:                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m \"I'm searching for subtle clues in the text. Classify it as 1 (positive) if it conveys enthusiasm, excitement,  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m or approval about a movie, product, or experience, and explicitly mentions its plot, characters, settings, or   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m features. However, classify it as 0 (negative) if it expresses criticism, dissatisfaction, or negativity        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m towards an entity, even with caveats or qualifications, especially when characterized by rhetorical questions,  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m emotive language, personal attacks, and explicit criticism. Be cautious of false positives in reviews;          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prioritize the presence of objective statements, balanced evaluations, and detailed analysis. If the text       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m appears to be a rant or complaint, pay attention to its tone, structure, and author's purpose. Specifically,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m consider whether the text mentions specific plot points, character interactions, or settings that align with    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the genre (e.g., action movie), and take note of any requests for release, restoration, or improvement related  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m to an old movie or entity.\"                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Analysis of misclassifications:                                                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         **Analysis of Misclassifications**                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m The provided texts demonstrate a range of misclassifications, including:                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Negative texts classified as positive:**                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 1 (Movie Review): The text describes a movie as \"one of the cheapest action flicks of the     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m eighties\" and states it's \"really awful,\" but also mentions it's a \"great party tape.\" The model incorrectly    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classified this review as positive, likely due to the tone being more playful and humorous than negative.       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 2 (Sequel Review): This text discusses a movie that didn't live up to expectations, stating   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it's \"not a bad film\" but also mentions it's \"like most sequels.\" The model misclassified this review as        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive, possibly due to the reviewer's lukewarm tone and emphasis on its family-friendly nature.              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Positive texts classified as negative:**                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 3 (Movie Review): This text discusses a movie with a ridiculous plot, bad dialogue, and silly \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m characters, but also highlights its entertaining aspects, such as suspense and action sequences. The model      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m incorrectly classified this review as negative, likely due to the focus on the movie's flaws rather than its    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enjoyable qualities.                                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         * Example 4 (Historical Context Complaint): This text expresses disappointment with Paramount Pictures' \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m handling of a historical movie, criticizing their restoration efforts and lack of recognition for a real pirate \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m who lived in New Orleans. The model misclassified this complaint as negative, possibly due to the tone being    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m more critical than positive.                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Correct Classifications**                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m For each example:                                                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Example 1**: Correct classification should be Negative (0)                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Example 2**: Correct classification should be Positive (1) with a nuance: it's a mediocre movie that       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m didn't live up to expectations, but still enjoyable for some.                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Example 3**: Correct classification should be Positive (1), highlighting the movie's entertaining aspects  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and flaws as a sign of its campy appeal.                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Example 4**: Correct classification should be Negative (0), emphasizing the complainant's disappointment   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m with Paramount Pictures' handling of a historical movie.                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to Improve Classification Prompt**                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m To reduce false positives and false negatives, consider the following adjustments:                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Tone Analysis**: Incorporate tone analysis techniques into the prompt to better capture the nuances of     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m language. This can help distinguish between playful or humorous texts that are still negative and those that    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m genuinely express enthusiasm.                                                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Emphasis on Specifics**: Encourage the model to focus on specific details in the text, such as plot        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m elements, character development, or historical context. This can help identify whether a review is primarily    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m positive or negative.                                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Contextual Understanding**: Add contextual understanding to the prompt by incorporating information about  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the movie's genre, target audience, and release date. This can help the model recognize that a negative review  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m might still be enjoyable for some viewers.                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Sentiment Polarity**: Refine the sentiment polarity analysis in the prompt to account for subtle           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m differences between positive and negative sentiments. This can involve identifying nuance in language, such as  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m using words like \"awful\" versus \"bad.\"                                                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 5. **Regular Training Data Updates**: Regularly update the training data with new texts that reflect different  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m genres, styles, and linguistic variations. This will help ensure the model remains accurate and adaptable to    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m changing language patterns.                                                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By incorporating these strategies into the classification prompt, you can improve its accuracy in recognizing   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m the nuances of language and reduce false positives and false negatives.                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         Your task is to provide a rewritten, production-ready version of the prompt that improves its accuracy. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m         IMPORTANT note: the prompt should not include any preamble or request for explanations, just the final  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prompt itself.                                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Iteration </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mIteration \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m/\u001b[0m\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭─────────────────────────────── System Prompt ────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Here's the refined prompt:  \"I'm searching for subtle clues in the text.     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Classify it as 1 (positive) if it conveys genuine enthusiasm, excitement, or <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> approval about a movie, product, or experience, and explicitly mentions its  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> plot, characters, settings, or features. However, classify it as 0           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> (negative) if it expresses criticism, dissatisfaction, or negativity towards <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> an entity, even with caveats or qualifications, especially when              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> characterized by rhetorical questions, emotive language, personal attacks,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> and explicit criticism. Be cautious of false positives in reviews;           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> prioritize the presence of objective statements, balanced evaluations, and   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> detailed analysis. If the text appears to be a rant or complaint, pay        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> attention to its tone, structure, and author's purpose.  To refine my        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classification, consider the following:  * Tone: distinguish between playful <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> or humorous texts that are still negative and those that genuinely express   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enthusiasm. * Emphasis on specifics: focus on specific details in the text,  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> such as plot elements, character development, or historical context. *       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Contextual understanding: take into account information about the movie's    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> genre, target audience, and release date to recognize that a negative review <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> might still be enjoyable for some viewers. * Sentiment polarity: identify    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> nuanced differences between positive and negative sentiments, accounting for <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> words like \"awful\" versus \"bad\". * Specifics in criticism: pay attention to  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> whether the text mentions specific plot points, character interactions, or   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> settings that align with the genre (e.g., action movie). * Author's intent:  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> consider whether the text is primarily a request for release, restoration,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> or improvement related to an old movie or entity. * Nuanced evaluations:     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classify texts that express mixed opinions or ambivalence as 1 (positive) if <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> they highlight enjoyable aspects, and 0 (negative) if they emphasize flaws.\" <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> You are to respond strictly in binary format. For each question, reply only  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> with '1' for positive or '0' for negative. Do not include any other text,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> explanations, or comments.                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰──────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m──────────────────────────────\u001b[0m\u001b[1m System Prompt \u001b[0m\u001b[1m───────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Here's the refined prompt:  \"I'm searching for subtle clues in the text.     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Classify it as 1 (positive) if it conveys genuine enthusiasm, excitement, or \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m approval about a movie, product, or experience, and explicitly mentions its  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m plot, characters, settings, or features. However, classify it as 0           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m (negative) if it expresses criticism, dissatisfaction, or negativity towards \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m an entity, even with caveats or qualifications, especially when              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m characterized by rhetorical questions, emotive language, personal attacks,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m and explicit criticism. Be cautious of false positives in reviews;           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m prioritize the presence of objective statements, balanced evaluations, and   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m detailed analysis. If the text appears to be a rant or complaint, pay        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m attention to its tone, structure, and author's purpose.  To refine my        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classification, consider the following:  * Tone: distinguish between playful \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m or humorous texts that are still negative and those that genuinely express   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enthusiasm. * Emphasis on specifics: focus on specific details in the text,  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m such as plot elements, character development, or historical context. *       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Contextual understanding: take into account information about the movie's    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m genre, target audience, and release date to recognize that a negative review \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m might still be enjoyable for some viewers. * Sentiment polarity: identify    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m nuanced differences between positive and negative sentiments, accounting for \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m words like \"awful\" versus \"bad\". * Specifics in criticism: pay attention to  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m whether the text mentions specific plot points, character interactions, or   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m settings that align with the genre (e.g., action movie). * Author's intent:  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m consider whether the text is primarily a request for release, restoration,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m or improvement related to an old movie or entity. * Nuanced evaluations:     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classify texts that express mixed opinions or ambivalence as 1 (positive) if \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m they highlight enjoyable aspects, and 0 (negative) if they emphasize flaws.\" \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m You are to respond strictly in binary format. For each question, reply only  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m with '1' for positive or '0' for negative. Do not include any other text,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m explanations, or comments.                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 2/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 3/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 4/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 6/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 8/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 10/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 11/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 12/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 13/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 15/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 16/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 17/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 18/40\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 19/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 20/40\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 21/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 22/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 23/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 24/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 25/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 26/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 27/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 28/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 29/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 30/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 31/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 32/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 33/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 34/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 35/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 36/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 37/40\n",
      "Prediction: 0 | Ground Truth: 1 ❌ (FN)\n",
      "Processing text 38/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 39/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 40/40\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "\n",
      "Number of invalid predictions: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 5</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.9000 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.9000 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 5\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.9000 │\n",
       "│ Recall              │ 0.9000 │\n",
       "│ Accuracy            │ 0.9000 │\n",
       "│ F1-score            │ 0.9000 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Best prompt based on F1-score:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mBest prompt based on F1-score:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    │\n",
       "│                                                                                                                 │\n",
       "│ You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for    │\n",
       "│ negative. Do not include any other text, explanations, or comments.                                             │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    │\n",
       "│                                                                                                                 │\n",
       "│ You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for    │\n",
       "│ negative. Do not include any other text, explanations, or comments.                                             │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Comparison of All Iterations                         </span>\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Iteration </span>┃<span style=\"font-weight: bold\"> Precision </span>┃<span style=\"font-weight: bold\"> Recall </span>┃<span style=\"font-weight: bold\"> Accuracy </span>┃<span style=\"font-weight: bold\"> F1-score </span>┃<span style=\"font-weight: bold\"> Invalid Predictions </span>┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    0.8333 │ <span style=\"font-weight: bold\">1.0000</span> │   <span style=\"font-weight: bold\">0.9000</span> │   <span style=\"font-weight: bold\">0.9091</span> │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     2     │    0.8182 │ 0.9000 │   0.8500 │   0.8571 │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     3     │    0.8571 │ 0.9000 │   0.8750 │   0.8780 │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     4     │    <span style=\"font-weight: bold\">0.9000</span> │ 0.9000 │   <span style=\"font-weight: bold\">0.9000</span> │   0.9000 │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "│     5     │    <span style=\"font-weight: bold\">0.9000</span> │ 0.9000 │   <span style=\"font-weight: bold\">0.9000</span> │   0.9000 │              <span style=\"font-weight: bold\">0.0000</span> │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Comparison of All Iterations                         \u001b[0m\n",
       "┏━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIteration\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInvalid Predictions\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│     1     │    0.8333 │ \u001b[1m1.0000\u001b[0m │   \u001b[1m0.9000\u001b[0m │   \u001b[1m0.9091\u001b[0m │              \u001b[1m0.0000\u001b[0m │\n",
       "│     2     │    0.8182 │ 0.9000 │   0.8500 │   0.8571 │              \u001b[1m0.0000\u001b[0m │\n",
       "│     3     │    0.8571 │ 0.9000 │   0.8750 │   0.8780 │              \u001b[1m0.0000\u001b[0m │\n",
       "│     4     │    \u001b[1m0.9000\u001b[0m │ 0.9000 │   \u001b[1m0.9000\u001b[0m │   0.9000 │              \u001b[1m0.0000\u001b[0m │\n",
       "│     5     │    \u001b[1m0.9000\u001b[0m │ 0.9000 │   \u001b[1m0.9000\u001b[0m │   0.9000 │              \u001b[1m0.0000\u001b[0m │\n",
       "└───────────┴───────────┴────────┴──────────┴──────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All logs saved in directory: prompt_optimization_logs_20240919_133925\n"
     ]
    }
   ],
   "source": [
    "# Start the prompt optimization process\n",
    "optimize_prompt(initial_prompt, output_format_prompt, eval_data, iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

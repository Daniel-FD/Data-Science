{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "# Use getcwd() to get the current working directory for Jupyter notebooks\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from src.iterative_prompt_optimization import optimize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data shape: (20, 2)\n",
      "                                                text  label\n",
      "0  I hate guns and have never murdered anyone, bu...      0\n",
      "1  \"A Cry in the Dark\" is a masterful piece of ci...      1\n",
      "2  I was watching the Perfect Storm, and thought ...      1\n",
      "3  If you ask me the first one was really better ...      0\n",
      "4  The movie 'Heart of Darkness', based on the 18...      0\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "eval_data = pd.read_csv('reviews.csv', encoding='ISO-8859-1', usecols=['Text', 'Sentiment'])\n",
    "eval_data.columns = ['text', 'label']\n",
    "# Randomly select 50 positive and 50 negative samples\n",
    "eval_data = (\n",
    "    eval_data.groupby('label')\n",
    "    .apply(lambda x: x.sample(n=10, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Shuffle the DataFrame randomly\n",
    "eval_data = eval_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Evaluation data shape: {eval_data.shape}\")\n",
    "print(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial prompt and output format\n",
    "initial_prompt = (\n",
    "    \"You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.\"\n",
    ")\n",
    "\n",
    "output_format_prompt = (\n",
    "    \"You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for negative. \"\n",
    "    \"Do not include any other text, explanations, or comments.\"\n",
    ")\n",
    "\n",
    "# Set number of optimization iterations\n",
    "iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected provider: ollama\n",
      "Selected model: llama3.1\n",
      "Estimated token usage: 534100\n",
      "Estimated cost: $0 API Costs - Running on Local Hardware\n",
      "\n",
      "Do you want to proceed with the optimization? (Y/N): \n",
      "Iteration 1/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭───────────────────────────────────────────────── System Prompt ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> negative. Do not include any other text, explanations, or comments.                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m System Prompt \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m You are a sentiment analysis classifier. Determine whether the provided text expresses a positive sentiment.    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m negative. Do not include any other text, explanations, or comments.                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 2/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 3/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 4/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 6/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 9/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 10/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 11/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 12/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 13/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 15/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 16/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 17/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 18/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 19/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 20/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "\n",
      "Number of invalid predictions: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 1</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.7692 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.8500 │\n",
       "│ F1-score            │ 0.8696 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 1\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.7692 │\n",
       "│ Recall              │ 1.0000 │\n",
       "│ Accuracy            │ 0.8500 │\n",
       "│ F1-score            │ 0.8696 │\n",
       "│ Invalid Predictions │      0 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Analysis of Misclassifications**                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Upon analyzing the provided texts, I've identified specific examples where the LLM model made mistakes.         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **False Positives (Negative texts incorrectly classified as positive)**                                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Example 1**: \"I hate guns and have never murdered anyone...\" This text starts with a strong negative       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sentiment towards violence, but then describes a hypothetical situation where the protagonist would kill their  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> attacker. However, this scenario is portrayed in a way that suggests it's justified or even desirable. The      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> model might have misinterpreted the tone of this passage, mistaking it for a positive review due to its         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> enthusiastic language and use of phrases like \"Good call\" and \"'Hostel'-type film.\" **Correct classification:** <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Negative                                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Example 2**: \"I have seen this movie several times, it sure is one of the cheapest action flicks of the    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> eighties.\" This text starts with a clear negative statement about the movie's quality but ends by recommending  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it as \"great trash\" for those who enjoy cheap action movies. The model might have misjudged the tone and        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> focused on the phrase \"great party tape!\" which could be perceived as positive. **Correct classification:**     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Negative                                                                                                        <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Example 3**: This film is a mediocre, low-budget flick... This text is straightforward in its negative     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> assessment of the movie. However, it also mentions that the MST3K version was \"priceless; one of the best       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> episodes ever.\" The model might have misinterpreted this as an endorsement of the original film itself instead  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> of the parody episode. **Correct classification:** Negative                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Insights and Strategies to Improve Classification**                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1.  **Improve tone detection**: Develop a more nuanced understanding of tone, particularly for texts that       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> express strong opinions or emotions.                                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2.  **Contextualize phrases and sentences**: Recognize when a single phrase or sentence might be misinterpreted <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> in isolation, and consider the context in which it appears.                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3.  **Avoid overreliance on individual words**: Instead, focus on the overall sentiment expressed by a text,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> even if that means considering multiple sentences or phrases.                                                   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4.  **Weighting factors for tone and content**: Consider developing a weighting system to account for different <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> factors that influence sentiment classification, such as the strength of opinions, emotional language, or       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> contextual clues.                                                                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Correct Classification Recommendations**                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1.  **Example 1**: This text should be classified as Negative due to its overall negative sentiment towards     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> violence.                                                                                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2.  **Example 2**: This text should also be classified as Negative because it explicitly states that the movie  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> is a \"cheap\" and low-quality film, even though it's recommended for those who enjoy such movies.                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3.  **Example 3**: Similarly, this text should be classified as Negative due to its overall negative assessment <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> of the original film.                                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Improved Prompt Strategies**                                                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1.  **Incorporate contextual information**: Encourage users to provide additional context about their reviews,  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> such as their expectations or the type of movie they were watching.                                             <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2.  **Use more nuanced sentiment labels**: Instead of using binary positive/negative labels, consider using a   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> three- or four-tiered system that captures varying levels of positivity and negativity (e.g., very negative,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> somewhat negative, neutral, etc.).                                                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3.  **Account for sarcasm and irony**: Develop strategies to detect when users are being sarcastic or ironic in <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> their reviews, which can significantly impact the accuracy of sentiment classification.                         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> By implementing these strategies and refining the prompt to better capture subtle differences in text, we       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> should be able to reduce false positives and false negatives and improve the overall accuracy of our binary     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classification model.                                                                                           <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Analysis of Misclassifications**                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Upon analyzing the provided texts, I've identified specific examples where the LLM model made mistakes.         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **False Positives (Negative texts incorrectly classified as positive)**                                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Example 1**: \"I hate guns and have never murdered anyone...\" This text starts with a strong negative       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sentiment towards violence, but then describes a hypothetical situation where the protagonist would kill their  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m attacker. However, this scenario is portrayed in a way that suggests it's justified or even desirable. The      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m model might have misinterpreted the tone of this passage, mistaking it for a positive review due to its         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m enthusiastic language and use of phrases like \"Good call\" and \"'Hostel'-type film.\" **Correct classification:** \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Negative                                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Example 2**: \"I have seen this movie several times, it sure is one of the cheapest action flicks of the    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m eighties.\" This text starts with a clear negative statement about the movie's quality but ends by recommending  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it as \"great trash\" for those who enjoy cheap action movies. The model might have misjudged the tone and        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m focused on the phrase \"great party tape!\" which could be perceived as positive. **Correct classification:**     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Negative                                                                                                        \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Example 3**: This film is a mediocre, low-budget flick... This text is straightforward in its negative     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m assessment of the movie. However, it also mentions that the MST3K version was \"priceless; one of the best       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m episodes ever.\" The model might have misinterpreted this as an endorsement of the original film itself instead  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m of the parody episode. **Correct classification:** Negative                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Insights and Strategies to Improve Classification**                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1.  **Improve tone detection**: Develop a more nuanced understanding of tone, particularly for texts that       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m express strong opinions or emotions.                                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2.  **Contextualize phrases and sentences**: Recognize when a single phrase or sentence might be misinterpreted \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m in isolation, and consider the context in which it appears.                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3.  **Avoid overreliance on individual words**: Instead, focus on the overall sentiment expressed by a text,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m even if that means considering multiple sentences or phrases.                                                   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4.  **Weighting factors for tone and content**: Consider developing a weighting system to account for different \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m factors that influence sentiment classification, such as the strength of opinions, emotional language, or       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m contextual clues.                                                                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Correct Classification Recommendations**                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1.  **Example 1**: This text should be classified as Negative due to its overall negative sentiment towards     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m violence.                                                                                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2.  **Example 2**: This text should also be classified as Negative because it explicitly states that the movie  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m is a \"cheap\" and low-quality film, even though it's recommended for those who enjoy such movies.                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3.  **Example 3**: Similarly, this text should be classified as Negative due to its overall negative assessment \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m of the original film.                                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Improved Prompt Strategies**                                                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1.  **Incorporate contextual information**: Encourage users to provide additional context about their reviews,  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m such as their expectations or the type of movie they were watching.                                             \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2.  **Use more nuanced sentiment labels**: Instead of using binary positive/negative labels, consider using a   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m three- or four-tiered system that captures varying levels of positivity and negativity (e.g., very negative,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m somewhat negative, neutral, etc.).                                                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3.  **Account for sarcasm and irony**: Develop strategies to detect when users are being sarcastic or ironic in \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m their reviews, which can significantly impact the accuracy of sentiment classification.                         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m By implementing these strategies and refining the prompt to better capture subtle differences in text, we       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m should be able to reduce false positives and false negatives and improve the overall accuracy of our binary     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classification model.                                                                                           \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n",
      "\n",
      "Iteration 2/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭───────────────────────────────────────────────── System Prompt ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Here's a refined prompt:                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> \"Classify this text as positive, negative, or neutral, taking into account contextual clues, tone, and language <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> nuances to accurately capture the overall sentiment. Consider potential sarcasm, irony, or strong opinions that <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> might influence your classification.\"                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> negative. Do not include any other text, explanations, or comments.                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m System Prompt \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Here's a refined prompt:                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \"Classify this text as positive, negative, or neutral, taking into account contextual clues, tone, and language \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m nuances to accurately capture the overall sentiment. Consider potential sarcasm, irony, or strong opinions that \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m might influence your classification.\"                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m You are to respond strictly in binary format. For each question, reply only with '1' for positive or '0' for    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m negative. Do not include any other text, explanations, or comments.                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 1/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 2/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 3/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 4/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 5/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 6/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 7/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 8/20\n",
      "Prediction: 101111010001 | Ground Truth: 0 🛠️ (Invalid Output Format)\n",
      "Processing text 9/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 10/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 11/20\n",
      "Prediction: 10111011100111 | Ground Truth: 1 🛠️ (Invalid Output Format)\n",
      "Processing text 12/20\n",
      "Prediction: 01010 | Ground Truth: 0 🛠️ (Invalid Output Format)\n",
      "Processing text 13/20\n",
      "Prediction: 0 | Ground Truth: 0 ✅ (TN)\n",
      "Processing text 14/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 15/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 16/20\n",
      "Prediction: 11101101010100011010 | Ground Truth: 1 🛠️ (Invalid Output Format)\n",
      "Processing text 17/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "Processing text 18/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 19/20\n",
      "Prediction: 1 | Ground Truth: 1 ✅ (TP)\n",
      "Processing text 20/20\n",
      "Prediction: 1 | Ground Truth: 0 ❌ (FP)\n",
      "\n",
      "Number of invalid predictions: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Evaluation Metrics - Iteration 2</span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metric              </span>┃<span style=\"font-weight: bold\">  Value </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.5833 │\n",
       "│ Recall              │ 0.8750 │\n",
       "│ Accuracy            │ 0.6250 │\n",
       "│ F1-score            │ 0.7000 │\n",
       "│ Invalid Predictions │      4 │\n",
       "└─────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mEvaluation Metrics - Iteration 2\u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetric             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m Value\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ Precision           │ 0.5833 │\n",
       "│ Recall              │ 0.8750 │\n",
       "│ Accuracy            │ 0.6250 │\n",
       "│ F1-score            │ 0.7000 │\n",
       "│ Invalid Predictions │      4 │\n",
       "└─────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing misclassifications...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">╭──────────────────────────────────────── Analysis of Misclassifications ─────────────────────────────────────────╮</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> After analyzing the misclassifications, I've identified specific examples from each set where the model made a  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> mistake and highlighted what elements of the text may have led to the incorrect classification.                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Negative (0) texts incorrectly classified as positive:**                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Text 3:** The movie \"Dragon Hunt\" is described as \"one of the cheapest action flicks of the eighties,\"     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> which should have been classified as negative. However, the model was swayed by phrases like \"but then again,   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> it is a great party tape!\" and \"if you are into great trash...\" which may have misled it to think this text was <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> more positive than negative.                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Text 4:** The movie review starts with \"What starts out as a passable movie degenerates into one of the    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> most incoherent, UNscary, incompetently made, stupid attempted horror films...\" which is clearly a scathing     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> critique. However, the model may have been fooled by the phrase \"starts out\" implying some redeeming qualities. <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Text 5:** This text is an attack on the movie's depiction of Islam and its production values. The language <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> used (\"horribly inaccurate,\" \"lack of attention to the most basic standards of journalism\") should have clearly <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> classified it as negative.                                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Text 6:** Although this text is a positive review, the model may have been confused by the comparison with <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Rush Limbaugh's radio show. The phrase \"you'll get the same message with the same level of intellectual         <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> analysis\" might have led the model to think it was more negative than positive.                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Positives (0) texts incorrectly classified as negative:**                                                     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Text 1:** This review of the movie adaptation of \"Heart of Darkness\" is strongly critical, using phrases   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> like \"one with little to no detail and has an almost schizophrenic like plot line.\" However, it's clear that    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> this criticism is based on a comparison with the book, which might have misled the model.                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Text 2:** The review of the Dillinger movie is scathing, describing it as \"horribly inaccurate\" and saying <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> that the viewer would not have enjoyed it even without reading the book. This should have clearly classified it <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> as negative.                                                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Negative                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Text 7:** Although this text is a positive review of the American Pie movie, the model may have been       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> confused by the phrase \"found the humor and the plot to be far more engaging audience than any of the American  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Pie movies to date.\" The use of the word \"audience\" might have suggested that the reviewer was thinking about a <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> broader context.                                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> Correct classification: Positive                                                                                <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Insights into why these errors occurred:**                                                                    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Lack of nuance:** The model may not be sensitive enough to the nuances of language, leading it to          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> misinterpret certain phrases or sentences.                                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Contextual understanding:** The model might struggle to understand the context in which certain words or   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> phrases are used, leading to incorrect classification.                                                          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Overemphasis on specific keywords:** The model may rely too heavily on specific keywords or phrases,       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> rather than considering the overall sentiment and context.                                                      <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> **Strategies to improve the classification prompt:**                                                            <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 1. **Use more nuanced sentiment analysis techniques:** Incorporate techniques that can better capture subtle    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> differences in language, such as aspect-based sentiment analysis.                                               <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 2. **Train the model with a broader range of texts:** Include texts from various domains, styles, and authors   <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> to help the model develop a deeper understanding of language and context.                                       <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 3. **Use contextual information:** Consider using additional information about the text, such as its source,    <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> author, or historical context, to improve classification accuracy.                                              <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> 4. **Regularly evaluate and update the model:** Continuously assess the model's performance on new data and     <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> make updates to address any biases or shortcomings that emerge.                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> These strategies should help reduce both false positives and false negatives by making the prompt more          <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span> sensitive to subtle differences in the classification of text.                                                  <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">│</span>                                                                                                                 <span style=\"font-weight: bold\">│</span>\n",
       "<span style=\"font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m╭─\u001b[0m\u001b[1m───────────────────────────────────────\u001b[0m\u001b[1m Analysis of Misclassifications \u001b[0m\u001b[1m────────────────────────────────────────\u001b[0m\u001b[1m─╮\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m After analyzing the misclassifications, I've identified specific examples from each set where the model made a  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m mistake and highlighted what elements of the text may have led to the incorrect classification.                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Negative (0) texts incorrectly classified as positive:**                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Text 3:** The movie \"Dragon Hunt\" is described as \"one of the cheapest action flicks of the eighties,\"     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m which should have been classified as negative. However, the model was swayed by phrases like \"but then again,   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m it is a great party tape!\" and \"if you are into great trash...\" which may have misled it to think this text was \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m more positive than negative.                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Text 4:** The movie review starts with \"What starts out as a passable movie degenerates into one of the    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m most incoherent, UNscary, incompetently made, stupid attempted horror films...\" which is clearly a scathing     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m critique. However, the model may have been fooled by the phrase \"starts out\" implying some redeeming qualities. \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Text 5:** This text is an attack on the movie's depiction of Islam and its production values. The language \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m used (\"horribly inaccurate,\" \"lack of attention to the most basic standards of journalism\") should have clearly \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m classified it as negative.                                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Text 6:** Although this text is a positive review, the model may have been confused by the comparison with \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Rush Limbaugh's radio show. The phrase \"you'll get the same message with the same level of intellectual         \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m analysis\" might have led the model to think it was more negative than positive.                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Positives (0) texts incorrectly classified as negative:**                                                     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Text 1:** This review of the movie adaptation of \"Heart of Darkness\" is strongly critical, using phrases   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m like \"one with little to no detail and has an almost schizophrenic like plot line.\" However, it's clear that    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m this criticism is based on a comparison with the book, which might have misled the model.                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Text 2:** The review of the Dillinger movie is scathing, describing it as \"horribly inaccurate\" and saying \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m that the viewer would not have enjoyed it even without reading the book. This should have clearly classified it \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m as negative.                                                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Negative                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Text 7:** Although this text is a positive review of the American Pie movie, the model may have been       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m confused by the phrase \"found the humor and the plot to be far more engaging audience than any of the American  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Pie movies to date.\" The use of the word \"audience\" might have suggested that the reviewer was thinking about a \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m broader context.                                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m Correct classification: Positive                                                                                \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Insights into why these errors occurred:**                                                                    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Lack of nuance:** The model may not be sensitive enough to the nuances of language, leading it to          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m misinterpret certain phrases or sentences.                                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Contextual understanding:** The model might struggle to understand the context in which certain words or   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m phrases are used, leading to incorrect classification.                                                          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Overemphasis on specific keywords:** The model may rely too heavily on specific keywords or phrases,       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m rather than considering the overall sentiment and context.                                                      \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m **Strategies to improve the classification prompt:**                                                            \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 1. **Use more nuanced sentiment analysis techniques:** Incorporate techniques that can better capture subtle    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m differences in language, such as aspect-based sentiment analysis.                                               \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 2. **Train the model with a broader range of texts:** Include texts from various domains, styles, and authors   \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m to help the model develop a deeper understanding of language and context.                                       \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 3. **Use contextual information:** Consider using additional information about the text, such as its source,    \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m author, or historical context, to improve classification accuracy.                                              \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m 4. **Regularly evaluate and update the model:** Continuously assess the model's performance on new data and     \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m make updates to address any biases or shortcomings that emerge.                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m These strategies should help reduce both false positives and false negatives by making the prompt more          \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m sensitive to subtle differences in the classification of text.                                                  \u001b[1m│\u001b[0m\n",
       "\u001b[1m│\u001b[0m                                                                                                                 \u001b[1m│\u001b[0m\n",
       "\u001b[1m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating new prompt...\n"
     ]
    }
   ],
   "source": [
    "optimize_prompt(initial_prompt, output_format_prompt, eval_data, iterations, \n",
    "                   model_provider=\"ollama\", model_name=\"llama3.1\")\n",
    "# After running the optimization process, you can analyze the results by checking \n",
    "# the generated log files in the `runs/prompt_optimization_logs_YYYYMMDD_HHMMSS` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the prompt optimization process\n",
    "# optimize_prompt(initial_prompt, output_format_prompt, eval_data, iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
